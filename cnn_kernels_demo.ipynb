{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e52c906",
   "metadata": {},
   "source": [
    "\n",
    "# Demo: Convoluciones clásicas y una CNN mínima en PyTorch\n",
    "\n",
    "Este cuaderno muestra:\n",
    "1. Cómo **aplicar kernels (filtros)** clásicos mediante convolución 2D en PyTorch (Sobel, Laplaciano, Blur, Sharpen, Emboss, etc.).  \n",
    "2. Una **CNN mínima** y la **visualización de mapas de activación** (feature maps) de su primera capa para una imagen de ejemplo.  \n",
    "3. **(Opcional)** un entrenamiento rápido sobre MNIST para comparar activaciones **antes** y **después** del entrenamiento.\n",
    "\n",
    "> Sugerencias docentes: cambia los valores de los kernels y observa el efecto, combina filtros (e.g., Blur → Sobel), y modifica tamaño de kernel/`padding`/`stride`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80260e4",
   "metadata": {},
   "source": [
    "## Importaciones y utilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c88d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import os, math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# Utilidades de visualización\n",
    "# ----------------------------\n",
    "def imshow_gray(t, title=None):\n",
    "    \"\"\"\n",
    "    Muestra un tensor imagen [H,W] o [1,H,W] en escala de grises.\n",
    "    \"\"\"\n",
    "    if isinstance(t, torch.Tensor):\n",
    "        tt = t\n",
    "    else:\n",
    "        tt = torch.as_tensor(t)\n",
    "    if tt.dim() == 3:\n",
    "        tt = tt.squeeze(0)\n",
    "    tt = tt.detach().cpu().numpy()\n",
    "    plt.figure()\n",
    "    plt.imshow(tt, cmap='gray', vmin=tt.min(), vmax=tt.max())\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "def grid_show(tensor_list, titles=None, ncols=3, suptitle=None):\n",
    "    \"\"\"\n",
    "    Muestra una lista de tensores [H,W] o [1,H,W] en una grilla.\n",
    "    \"\"\"\n",
    "    n = len(tensor_list)\n",
    "    ncols = min(ncols, n)\n",
    "    nrows = math.ceil(n / ncols)\n",
    "    import numpy as _np\n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(3*ncols, 3*nrows))\n",
    "    if nrows == 1 and ncols == 1:\n",
    "        axes = _np.array([[axes]])\n",
    "    elif nrows == 1:\n",
    "        axes = _np.array([axes])\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < n:\n",
    "            t = tensor_list[i]\n",
    "            if isinstance(t, torch.Tensor):\n",
    "                tt = t\n",
    "            else:\n",
    "                tt = torch.as_tensor(t)\n",
    "            if tt.dim() == 3:\n",
    "                tt = tt.squeeze(0)\n",
    "            ax.imshow(tt.detach().cpu().numpy(), cmap='gray')\n",
    "            ax.axis('off')\n",
    "            if titles and i < len(titles):\n",
    "                ax.set_title(titles[i])\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    if suptitle:\n",
    "        fig.suptitle(suptitle)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dcbe648",
   "metadata": {},
   "source": [
    "## Imagen sintética de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d95191",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def synthetic_checkerboard(H=128, W=128, block=8):\n",
    "    \"\"\"Tablero de cuadros = buen patrón para ver bordes.\"\"\"\n",
    "    yy, xx = np.indices((H, W))\n",
    "    board = ((yy // block + xx // block) % 2).astype(np.float32)\n",
    "    return torch.from_numpy(board)  # [H, W], 0/1\n",
    "\n",
    "def synthetic_gradient_circle(H=128, W=128, r0=50):\n",
    "    \"\"\"Círculo suave sobre gradiente para ver realces.\"\"\"\n",
    "    yy, xx = np.indices((H, W))\n",
    "    cy, cx = H//2, W//2\n",
    "    dist = np.sqrt((yy-cy)**2 + (xx-cx)**2)\n",
    "    circle = (dist < r0).astype(np.float32)\n",
    "    gradx = (xx / (W-1)).astype(np.float32)\n",
    "    base = 0.6*gradx + 0.4*circle\n",
    "    return torch.from_numpy(base)\n",
    "\n",
    "# Combinamos ambas para una escena simple:\n",
    "img1 = synthetic_checkerboard(128, 128, block=8)  # [H,W]\n",
    "img2 = synthetic_gradient_circle(128, 128, r0=38) # [H,W]\n",
    "img = 0.5*img1 + 0.5*img2\n",
    "img = (img - img.min()) / (img.max() - img.min())\n",
    "x = img.unsqueeze(0).unsqueeze(0)  # [B=1, C=1, H, W]\n",
    "\n",
    "imshow_gray(img, title=\"Imagen sintética (grises)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d4cd41",
   "metadata": {},
   "source": [
    "## Definición y aplicación de kernels 3×3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c96f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def make_kernel(array2d):\n",
    "    k = torch.tensor(array2d, dtype=torch.float32)\n",
    "    k = k.unsqueeze(0).unsqueeze(0)  # [out_channels=1, in_channels=1, kH, kW]\n",
    "    return k\n",
    "\n",
    "# Kernels clásicos 3x3\n",
    "identity = make_kernel([[0,0,0],\n",
    "                        [0,1,0],\n",
    "                        [0,0,0]])\n",
    "\n",
    "blur = (1/9.0) * make_kernel([[1,1,1],\n",
    "                              [1,1,1],\n",
    "                              [1,1,1]])\n",
    "\n",
    "sharpen = make_kernel([[0,-1, 0],\n",
    "                       [-1,5,-1],\n",
    "                       [0,-1, 0]])\n",
    "\n",
    "edge_laplacian = make_kernel([[0, 1, 0],\n",
    "                              [1,-4, 1],\n",
    "                              [0, 1, 0]])\n",
    "\n",
    "sobel_x = make_kernel([[-1,0,1],\n",
    "                       [-2,0,2],\n",
    "                       [-1,0,1]])\n",
    "\n",
    "sobel_y = make_kernel([[-1,-2,-1],\n",
    "                       [ 0, 0, 0],\n",
    "                       [ 1, 2, 1]])\n",
    "\n",
    "emboss = make_kernel([[-2,-1, 0],\n",
    "                      [-1, 1, 1],\n",
    "                      [ 0, 1, 2]])\n",
    "\n",
    "kernels = {\n",
    "    \"Identity\": identity,\n",
    "    \"Blur (3x3)\": blur,\n",
    "    \"Sharpen\": sharpen,\n",
    "    \"Laplacian\": edge_laplacian,\n",
    "    \"Sobel X\": sobel_x,\n",
    "    \"Sobel Y\": sobel_y,\n",
    "    \"Emboss\": emboss,\n",
    "}\n",
    "\n",
    "def apply_kernel(x, k):\n",
    "    # x: [1,1,H,W], k: [1,1,kH,kW]\n",
    "    y = F.conv2d(x, k, padding='same')  # PyTorch >= 2.0\n",
    "    # Normalizar para visualizar mejor:\n",
    "    y = (y - y.min()) / (y.max() - y.min() + 1e-8)\n",
    "    return y.squeeze(0).squeeze(0)\n",
    "\n",
    "filtered = []\n",
    "titles = []\n",
    "for name, k in kernels.items():\n",
    "    y = apply_kernel(x, k)\n",
    "    filtered.append(y)\n",
    "    titles.append(name)\n",
    "\n",
    "grid_show([img] + filtered, titles=[\"Original\"] + titles, ncols=4,\n",
    "          suptitle=\"Convolución con kernels clásicos\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63eeeac2",
   "metadata": {},
   "source": [
    "## CNN mínima y visualización de mapas de activación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a704815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class SmallCNN(nn.Module):\n",
    "    def __init__(self, n_classes=10):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=3, padding=1)   # 1->8\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, padding=1)  # 8->16\n",
    "        self.pool = nn.MaxPool2d(2,2)  # reduce H,W a la mitad\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*7*7, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, n_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = F.relu(self.conv1(z))  # [B,8,H,W]\n",
    "        z = self.pool(z)           # [B,8,H/2,W/2]\n",
    "        z = F.relu(self.conv2(z))  # [B,16,H/2,W/2]\n",
    "        z = self.pool(z)           # [B,16,H/4,W/4]\n",
    "        z = self.head(z)\n",
    "        return z\n",
    "\n",
    "# Redimensionamos la imagen sintética a 28x28 (estilo MNIST) para pasarla por la CNN\n",
    "img28 = F.interpolate(x, size=(28,28), mode='bilinear', align_corners=False)  # [1,1,28,28]\n",
    "net = SmallCNN(n_classes=10).eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    a1 = F.relu(net.conv1(img28))  # [1, 8, 28, 28]\n",
    "\n",
    "# Visualizamos los 8 mapas (canales) de la primera conv\n",
    "chans = a1.squeeze(0)  # [8, 28, 28]\n",
    "grid_show([chans[i] for i in range(chans.size(0))],\n",
    "          titles=[f\"Conv1 map {i}\" for i in range(chans.size(0))],\n",
    "          ncols=4,\n",
    "          suptitle=\"Mapas de activación - Conv1 (sin entrenamiento)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5193e99",
   "metadata": {},
   "source": [
    "\n",
    "## (Opcional) Entrenamiento rápido en MNIST\n",
    "\n",
    "Ejecuta la celda para entrenar 1–2 épocas. Requiere `torchvision`.  \n",
    "Al final, visualiza de nuevo los mapas de activación de `conv1` para comparar **antes vs. después**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cb09c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_quick_mnist(epochs=1, batch_size=128, lr=1e-3, device='cpu'):\n",
    "    try:\n",
    "        import torchvision\n",
    "        from torchvision import transforms\n",
    "    except ImportError:\n",
    "        print(\"torchvision no está instalado. Omite el entrenamiento opcional.\")\n",
    "        return None, None\n",
    "\n",
    "    device = torch.device(device)\n",
    "    tfm = transforms.Compose([transforms.ToTensor()])  # [0,1], [C,H,W]\n",
    "    train_set = torchvision.datasets.MNIST(root=\"./data\", train=True, transform=tfm, download=True)\n",
    "    test_set  = torchvision.datasets.MNIST(root=\"./data\", train=False, transform=tfm, download=True)\n",
    "    train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "\n",
    "    model = SmallCNN(n_classes=10).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    def eval_acc():\n",
    "        model.eval()\n",
    "        correct = 0; total = 0\n",
    "        with torch.no_grad():\n",
    "            for xx, yy in test_loader:\n",
    "                xx, yy = xx.to(device), yy.to(device)\n",
    "                logits = model(xx)\n",
    "                pred = logits.argmax(1)\n",
    "                correct += (pred == yy).sum().item()\n",
    "                total += yy.numel()\n",
    "        return correct/total if total else 0.0\n",
    "\n",
    "    print(\"Entrenando (rápido) MNIST...\")\n",
    "    before = eval_acc()\n",
    "    print(f\"Accuracy inicial: {before:.3f}\")\n",
    "\n",
    "    model.train()\n",
    "    for ep in range(epochs):\n",
    "        for xx, yy in train_loader:\n",
    "            xx, yy = xx.to(device), yy.to(device)\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            logits = model(xx)\n",
    "            loss = loss_fn(logits, yy)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "        acc = eval_acc()\n",
    "        print(f\"Época {ep+1}/{epochs} - Accuracy: {acc:.3f}\")\n",
    "\n",
    "    return model, test_set\n",
    "\n",
    "# Descomenta para entrenar y visualizar activaciones después del entrenamiento:\n",
    "# model_trained, test_set = train_quick_mnist(epochs=2, device='cpu')\n",
    "# if model_trained is not None:\n",
    "#     model_trained.eval()\n",
    "#     # Tomamos una imagen del test y miramos Conv1\n",
    "#     x_ex, y_ex = test_set[0]\n",
    "#     with torch.no_grad():\n",
    "#         a1_after = F.relu(model_trained.conv1(x_ex.unsqueeze(0)))\n",
    "#     chans_after = a1_after.squeeze(0)\n",
    "#     grid_show([chans_after[i] for i in range(chans_after.size(0))],\n",
    "#               titles=[f\"Conv1 map {i} (entrenado)\" for i in range(chans_after.size(0))],\n",
    "#               ncols=4,\n",
    "#               suptitle=\"Mapas de activación - Conv1 (después de entrenar)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c750ff6",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Notas\n",
    "\n",
    "- En `apply_kernel`, se usa `padding='same'` (disponible en PyTorch ≥ 2.0). Si usas una versión anterior, reemplaza por `padding=1` para kernels 3×3.  \n",
    "- Para comparar PyTorch vs OpenCV, puedes replicar la sección de kernels con `cv2.filter2D` y observar diferencias numéricas (por normalización y bordes).  \n",
    "- Para ver los **filtros aprendidos**, inspecciona `net.conv1.weight` antes y después de entrenar con MNIST.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
